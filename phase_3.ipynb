{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Model Training and Evaluation\n",
    "\n",
    "Goals for this phase:\n",
    "\n",
    "1. Split the dataset into training, validation, and test sets.\n",
    "2. Train the model on the training set and monitor its performance on the validation set. \n",
    "3. Evaluate the model on the test set to get a final estimate of its performance."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load libraries and dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "from transformers import ElectraTokenizer, ElectraModel\n",
    "# from transformers import TinyBertTokenizer, TinyBertModel\n",
    "from transformers import MobileBertTokenizer, MobileBertModel"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (DistilBertTokenizer, DistilBertModel,\n",
    "                          BertTokenizer, BertModel,\n",
    "                          AlbertTokenizer, AlbertModel,\n",
    "                          ElectraTokenizer, ElectraModel,\n",
    "                          MobileBertTokenizer, MobileBertModel)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyemd import emd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
>>>>>>> f3c5b1b7c56f91a55db1f55108bb0c8e2b2f1c34
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Summary_Tokens</th>\n",
       "      <th>Content_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f49ee725a0360aa6881ed1f7999cc531885dd06a</td>\n",
       "      <td>New York police are concerned drones could bec...</td>\n",
       "      <td>Police have investigated criminals who have ri...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['Police', 'have', 'investigated', 'criminal',...</td>\n",
       "      <td>['New', 'York', 'police', 'are', 'concerned', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808fe317a53fbd3130c9b7563341a7eea6d15e94</td>\n",
       "      <td>By . Ryan Lipman . Perhaps Australian porn sta...</td>\n",
       "      <td>Porn star Angela White secretly filmed sex act...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['Porn', 'star', 'Angela', 'White', 'secretly'...</td>\n",
       "      <td>['By', '.', 'Ryan', 'Lipman', '.', 'Perhaps', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98fd67bd343e58bc4e275bbb5a4ea454ec827c0d</td>\n",
       "      <td>This was, Sergio Garcia conceded, much like be...</td>\n",
       "      <td>American draws inspiration from fellow country...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['American', 'draw', 'inspiration', 'from', 'f...</td>\n",
       "      <td>['This', 'was,', 'Sergio', 'Garcia', 'conceded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e12b5bd7056287049d9ec98e41dbb287bd19a981</td>\n",
       "      <td>An Ebola outbreak that began in Guinea four mo...</td>\n",
       "      <td>World Health Organisation: 635 infections and ...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['World', 'Health', 'Organisation:', '635', 'i...</td>\n",
       "      <td>['An', 'Ebola', 'outbreak', 'that', 'began', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b83e8bcfcd51419849160e789b6658b21a9aedcd</td>\n",
       "      <td>By . Associated Press and Daily Mail Reporter ...</td>\n",
       "      <td>A sinkhole opened up at 5:15am this morning in...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['A', 'sinkhole', 'opened', 'up', 'at', '5:15a...</td>\n",
       "      <td>['By', '.', 'Associated', 'Press', 'and', 'Dai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ID   \n",
       "0  f49ee725a0360aa6881ed1f7999cc531885dd06a  \\\n",
       "1  808fe317a53fbd3130c9b7563341a7eea6d15e94   \n",
       "2  98fd67bd343e58bc4e275bbb5a4ea454ec827c0d   \n",
       "3  e12b5bd7056287049d9ec98e41dbb287bd19a981   \n",
       "4  b83e8bcfcd51419849160e789b6658b21a9aedcd   \n",
       "\n",
       "                                             Content   \n",
       "0  New York police are concerned drones could bec...  \\\n",
       "1  By . Ryan Lipman . Perhaps Australian porn sta...   \n",
       "2  This was, Sergio Garcia conceded, much like be...   \n",
       "3  An Ebola outbreak that began in Guinea four mo...   \n",
       "4  By . Associated Press and Daily Mail Reporter ...   \n",
       "\n",
       "                                             Summary         Dataset   \n",
       "0  Police have investigated criminals who have ri...  CNN/Daily Mail  \\\n",
       "1  Porn star Angela White secretly filmed sex act...  CNN/Daily Mail   \n",
       "2  American draws inspiration from fellow country...  CNN/Daily Mail   \n",
       "3  World Health Organisation: 635 infections and ...  CNN/Daily Mail   \n",
       "4  A sinkhole opened up at 5:15am this morning in...  CNN/Daily Mail   \n",
       "\n",
       "                                      Summary_Tokens   \n",
       "0  ['Police', 'have', 'investigated', 'criminal',...  \\\n",
       "1  ['Porn', 'star', 'Angela', 'White', 'secretly'...   \n",
       "2  ['American', 'draw', 'inspiration', 'from', 'f...   \n",
       "3  ['World', 'Health', 'Organisation:', '635', 'i...   \n",
       "4  ['A', 'sinkhole', 'opened', 'up', 'at', '5:15a...   \n",
       "\n",
       "                                      Content_Tokens  \n",
       "0  ['New', 'York', 'police', 'are', 'concerned', ...  \n",
       "1  ['By', '.', 'Ryan', 'Lipman', '.', 'Perhaps', ...  \n",
       "2  ['This', 'was,', 'Sergio', 'Garcia', 'conceded...  \n",
       "3  ['An', 'Ebola', 'outbreak', 'that', 'began', '...  \n",
       "4  ['By', '.', 'Associated', 'Press', 'and', 'Dai...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the cleaned dataset\n",
    "df = pd.read_csv('data/cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the dataset\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "test_df = df.drop(train_df.index)"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Check if MPS is available\n",
    "use_mps = False\n",
    "if use_cuda:\n",
    "    try:\n",
    "        torch.cuda.amp.autocast()\n",
    "        use_mps = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Raise an error if neither CUDA nor MPS is available\n",
    "if not use_cuda and not use_mps:\n",
    "    raise RuntimeError(\"CUDA or MPS is required for training\")"
>>>>>>> f3c5b1b7c56f91a55db1f55108bb0c8e2b2f1c34
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define a function to prepare the input for the models\n",
    "def prepare_input(tokens, max_length, tokenizer):\n",
    "    # Prepare the input for the model\n",
    "    encoded_dict = tokenizer.encode_plus(tokens, max_length=max_length, \n",
    "                                          padding='max_length', truncation=True, \n",
    "                                          return_tensors='pt')\n",
    "    return {'input_ids': encoded_dict['input_ids'],\n",
    "            'attention_mask': encoded_dict['attention_mask']}\n",
    "# def prepare_input(tokens, max_length, tokenizer):\n",
    "#     # Prepare the input for the model\n",
    "#     encoded_dict = tokenizer.encode_plus(tokens, max_length=max_length, \n",
    "#                                           padding='max_length', truncation=True, \n",
    "#                                           return_tensors='pt')\n",
    "#     return encoded_dict\n",
    "\n",
    "def prepare_data(df, tokenizer):\n",
    "    # Convert the token columns to strings, and then to lists of tokens\n",
    "    df['Content_Tokens'] = df['Content_Tokens'].apply(lambda x: eval(str(x)))\n",
    "    df['Summary_Tokens'] = df['Summary_Tokens'].apply(lambda x: eval(str(x)))\n",
    "    \n",
    "    # Prepare the data for input into the models\n",
    "    df['Content_Input'] = df['Content_Tokens'].apply(prepare_input, args=(512,tokenizer,))\n",
    "    df['Summary_Input'] = df['Summary_Tokens'].apply(prepare_input, args=(128,tokenizer,))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def prepare_data(df, tokenizer):\n",
    "#     # Prepare the data for input into the models\n",
    "#     df['Content_Tokens'] = df['Content_Tokens'].apply(eval) # convert string representation to list of tokens\n",
    "#     df['Summary_Tokens'] = df['Summary_Tokens'].apply(eval) # convert string representation to list of tokens\n",
    "#     df['Content_Input'] = df['Content_Tokens'].apply(prepare_input, args=(512,tokenizer,))\n",
    "#     df['Summary_Input'] = df['Summary_Tokens'].apply(prepare_input, args=(128,tokenizer,))\n",
    "#     return df"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"cleaned.csv\")\n",
    "data.head()"
>>>>>>> f3c5b1b7c56f91a55db1f55108bb0c8e2b2f1c34
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Define a function to score the models\n",
    "# def score_model(model, input1, input2):\n",
    "#     # Generate embeddings for the inputs\n",
    "#     output1 = model(**input1)[1].detach().numpy()\n",
    "#     output2 = model(**input2)[1].detach().numpy()\n",
    "    \n",
    "#     # Calculate the Word Mover's Distance between the embeddings\n",
    "#     wmd = gensim.models.Word2Vec.euclidean_distances(output1, output2)\n",
    "    \n",
    "#     # Calculate the Smooth Inverse Frequency similarity between the embeddings\n",
    "#     sif = cosine_similarity(output1.mean(axis=0, keepdims=True), \n",
    "#                              output2.mean(axis=0, keepdims=True))[0][0]\n",
    "    \n",
    "#     return wmd, sif\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Step 5: Define a function to score the models\n",
    "def score_model(model, input1, input2):\n",
    "    # Generate embeddings for the inputs\n",
    "    output1 = model(**input1)[0].detach().numpy().mean(axis=1)\n",
    "    output2 = model(**input2)[0].detach().numpy().mean(axis=1)\n",
    "    \n",
    "    # Calculate the Word Mover's Distance between the embeddings\n",
    "    wmd = pairwise_distances(output1, output2, metric='euclidean')\n",
    "    \n",
    "    # Calculate the Smooth Inverse Frequency similarity between the embeddings\n",
    "    sif = cosine_similarity(output1.mean(axis=0, keepdims=True), \n",
    "                             output2.mean(axis=0, keepdims=True))[0][0]\n",
    "    \n",
    "    return wmd, sif\n",
    "\n",
    "\n"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop rows with no summary\n",
    "# data.dropna(subset=['summary'], inplace=True)\n",
    "\n",
    "# # Define stop words and lemmatizer\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "# # Tokenize and lemmatize the content\n",
    "# data['tokenized_content'] = data['content'].apply(lambda x: [lemmatizer.lemmatize(\n",
    "#     word) for word in word_tokenize(x.lower()) if word.isalpha() and word not in stop_words])"
>>>>>>> f3c5b1b7c56f91a55db1f55108bb0c8e2b2f1c34
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing MobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DistilBERT\n",
      "WMD Mean: 4.4856\n",
      "SIF Mean: 0.8400\n",
      "Model: MobileBERT\n",
      "WMD Mean: 2204752.0000\n",
      "SIF Mean: 0.9992\n",
      "Model: ALBERT\n",
      "WMD Mean: 15.5492\n",
      "SIF Mean: 0.8180\n",
      "Model: ELECTRA\n",
      "WMD Mean: 8.3385\n",
      "SIF Mean: 0.3745\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the models and compare their scores\n",
    "tokenizer_dict = {\n",
    "    'DistilBERT': DistilBertTokenizer.from_pretrained('distilbert-base-uncased'),\n",
    "    'MobileBERT': MobileBertTokenizer.from_pretrained('google/mobilebert-uncased'),\n",
    "    'ALBERT': AlbertTokenizer.from_pretrained('albert-base-v2'),\n",
    "    # 'TinyBERT': TinyBertTokenizer.from_pretrained('prajjwal1/bert-tiny'),\n",
    "    'ELECTRA': ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "}\n",
    "\n",
    "model_dict = {\n",
    "    'DistilBERT': DistilBertModel.from_pretrained('distilbert-base-uncased'),\n",
    "    'MobileBERT': MobileBertModel.from_pretrained('google/mobilebert-uncased'),\n",
    "    'ALBERT': AlbertModel.from_pretrained('albert-base-v2'),\n",
    "    # 'TinyBERT': TinyBertModel.from_pretrained('prajjwal1/bert-tiny'),\n",
    "    'ELECTRA': ElectraModel.from_pretrained('google/electra-small-discriminator')\n",
    "}\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for model_name in tokenizer_dict.keys():\n",
    "    tokenizer = tokenizer_dict[model_name]\n",
    "    model = model_dict[model_name]\n",
    "    train_df = prepare_data(train_df, tokenizer)\n",
    "    test_df = prepare_data(test_df, tokenizer)\n",
    "    scores = []\n",
    "    for i, row in test_df.iterrows():\n",
    "        content_input = row['Content_Input']\n",
    "        summary_input = row['Summary_Input']\n",
    "        wmd, sif = score_model(model, content_input, summary_input)\n",
    "        scores.append({'WMD': wmd, 'SIF': sif})\n",
    "    results_dict[model_name] = scores\n",
    "\n",
    "# Print the results\n",
    "for model_name, scores in results_dict.items():\n",
    "    wmd_scores = [score['WMD'] for score in scores]\n",
    "    sif_scores = [score['SIF'] for score in scores]\n",
    "    wmd_mean = np.mean(wmd_scores)\n",
    "    sif_mean = np.mean(sif_scores)\n",
    "    print(f'Model: {model_name}')\n",
    "    print(f'WMD Mean: {wmd_mean:.4f}')\n",
    "    print(f'SIF Mean: {sif_mean:.4f}')\n"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'distilbert-base-uncased': (DistilBertTokenizer, DistilBertModel),\n",
    "    'bert-base-uncased': (BertTokenizer, BertModel),\n",
    "    'albert-base-v2': (AlbertTokenizer, AlbertModel),\n",
    "    'google/electra-small-discriminator': (ElectraTokenizer, ElectraModel),\n",
    "    'google/mobilebert-uncased': (MobileBertTokenizer, MobileBertModel)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the similarity measures\n",
    "def smooth_inverse_frequency(word, doc_freqs, num_docs):\n",
    "    idf = np.log((num_docs + 1) / (doc_freqs[word] + 1))\n",
    "    return idf\n",
    "\n",
    "\n",
    "def word_movers_distance(model, tokenizer, doc1, doc2):\n",
    "    doc1_tokens = tokenizer.tokenize(doc1)\n",
    "    doc2_tokens = tokenizer.tokenize(doc2)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        doc1_embedding = model(\n",
    "            doc1, return_tensors=\"pt\").last_hidden_state.squeeze().detach().cpu().numpy()\n",
    "        doc2_embedding = model(\n",
    "            doc2, return_tensors=\"pt\").last_hidden_state.squeeze().detach().cpu().numpy()\n",
    "    else:\n",
    "        doc1_embedding = model(\n",
    "            doc1, return_tensors=\"pt\").last_hidden_state.squeeze().detach().numpy()\n",
    "        doc2_embedding = model(\n",
    "            doc2, return_tensors=\"pt\").last_hidden_state.squeeze().detach().numpy()\n",
    "    distance_matrix = cosine_similarity(doc1_embedding, doc2_embedding)\n",
    "    distance_matrix /= distance_matrix.max()\n",
    "    word2id = tokenizer.get_vocab()\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    doc1_counts = [doc1_tokens.count(id2word[i]) for i in range(len(word2id))]\n",
    "    doc2_counts = [doc2_tokens.count(id2word[i]) for i in range(len(word2id))]\n",
    "    doc_freqs = np.array([sum([1 for d in data['tokenized_content']\n",
    "                               if id2word[i] in d]) for i in range(len(word2id))])\n",
    "    num_docs = len(data['tokenized_content'])\n",
    "    doc1_sif = np.array([smooth_inverse_frequency(id2word[i], doc_freqs, num_docs) * doc1_counts[i]\n",
    "                            for i in range(len(word2id))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the models\n",
    "for model_name, (tokenizer_class, model_class) in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "    if use_mps:\n",
    "        model = model_class.from_pretrained(model_name).to(\n",
    "            device=torch.device('cuda'),\n",
    "            non_blocking=True).to(memory_format=torch.channels_last)\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    else:\n",
    "        model = model_class.from_pretrained(model_name).to(\n",
    "            device=torch.device('cuda'))\n",
    "        \n",
    "    num_docs = len(data)\n",
    "    doc_freqs = np.zeros(len(tokenizer))\n",
    "\n",
    "    for doc in data['tokenized_content']:\n",
    "        for word in set(doc):\n",
    "            doc_freqs[tokenizer.convert_tokens_to_ids(word)] += 1\n",
    "\n",
    "    doc_freqs = np.where(doc_freqs > 0, doc_freqs, 1)\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        summary = row['summary']\n",
    "        content = row['content']\n",
    "        tokenized_content = row['tokenized_content']\n",
    "\n",
    "        # Compute the TF-IDF weights for the tokenized content\n",
    "        vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "        tfidf_weights = vectorizer.fit_transform(tokenized_content)\n",
    "        tfidf_weights = tfidf_weights.toarray()\n",
    "\n",
    "        # Compute the weighted average embedding for the tokenized content\n",
    "        content_embedding = np.average(\n",
    "            tfidf_weights[:, :, np.newaxis] * model(tokenized_content,\n",
    "                                                    return_tensors=\"pt\").last_hidden_state.squeeze().detach().cpu().numpy(),\n",
    "            axis=1)\n",
    "        \n",
    "        # Compute the Word Mover's Distance and Smooth Inverse Frequency scores for the summary and each document\n",
    "        wmd_scores = []\n",
    "        sif_scores = []\n",
    "        for j, other_row in data.iterrows():\n",
    "            if i != j:\n",
    "                other_content = other_row['content']\n",
    "                other_tokenized_content = other_row['tokenized_content']\n",
    "                other_summary = other_row['summary']\n",
    "                other_tfidf_weights = vectorizer.transform(other_tokenized_content).toarray()\n",
    "                other_content_embedding = np.average(\n",
    "                    other_tfidf_weights[:, :, np.newaxis] * model(other_tokenized_content,\n",
    "                                                                   return_tensors=\"pt\").last_hidden_state.squeeze().detach().cpu().numpy(),\n",
    "                    axis=1)\n",
    "                wmd_score = word_movers_distance(model, tokenizer, summary, other_summary)\n",
    "                sif_score = cosine_similarity(content_embedding.reshape(1, -1),\n",
    "                                               other_content_embedding.reshape(1, -1),\n",
    "                                               smooth_inverse_frequency, doc_freqs, num_docs)\n",
    "                wmd_scores.append(wmd_score)\n",
    "                sif_scores.append(sif_score)\n",
    "\n",
    "        # Compute the average Word Mover's Distance and Smooth Inverse Frequency scores for the summary\n",
    "        avg_wmd_score = np.mean(wmd_scores)\n",
    "        avg_sif_score = np.mean(sif_scores)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Article ID: {row['id']}\")\n",
    "        print(f\"Word Mover's Distance: {avg_wmd_score}\")\n",
    "        print(f\"Smooth Inverse Frequency: {avg_sif_score}\")"
>>>>>>> f3c5b1b7c56f91a55db1f55108bb0c8e2b2f1c34
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
<<<<<<< HEAD
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
=======
   "name": "python",
>>>>>>> f3c5b1b7c56f91a55db1f55108bb0c8e2b2f1c34
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
